# 深度学习笔记

## 残差网络(ResNet)

残差网络主要用来解决深层网络中，随着层数越高，Feature Map包含的特征越小得问题，能够很好的在网络的高层和低层传递信息，残差网络主要由残差块构成，残差块的模型可以表示为：
$$
X_{i+1} = X_i + F(X_i, W_i)
$$
也就是在$i$层到$i+1$层的传递过程中，最后的输出为$i$层信息以及通过$i$层信息计算的Feature Map的和，这里两部分还存在层数不同的情况，那么就需要对$X_i$进行1x1卷积操作，以便升高维度或者降低维度。此时卷积块可以写成：
$$
X_{i+1} = H(X_i) + F(X_i, W_i)
$$

## 批正则化（BN）

对输入激活函数的数据进行小批量正则化（Mini batch SGD)，使得输入数据的尽量落在均值为0方差为1的区域。得到的好处有：

1） 加速训练

2）避免过拟合和梯度消失

计算原理：对于一个小批量数据$$X_i$$, 输出正则化的$y_i$，并且学习参数:$\gamma_i$ 和$\beta_i$res
$$
\mu_i = \frac{1}{m}\sum_m X_i
$$

$$
\sigma_i^2 = \frac{1}{m}\sum_m(X_i - \mu_i)^2
$$

$$
\hat{X_i} = \frac{X_i - \mu_i}{\sqrt{\sigma_i^2+\varepsilon}} 
$$

$$
y_i = \gamma_i\hat{X_i} + \beta_i
$$

